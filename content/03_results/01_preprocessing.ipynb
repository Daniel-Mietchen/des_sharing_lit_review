{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7f7cf0-f61f-4b5f-aff3-6c11059ab474",
   "metadata": {},
   "source": [
    "# Dataset pre-processing\n",
    "\n",
    "This notebook provides an overview of the code to read in the data extracted from the review.  \n",
    "\n",
    "The data set is held in a CSV file that has been an extracted from a Zotero library (TODO: INSERT Zotero library link).  The following data was then extracted from each paper\n",
    "\n",
    "* `study_included` - has the study been included in the final analysis\n",
    "* `model_code_available` - is the model made publically available in some manner\n",
    "* `reporting_guidelines_mention` - have reporting guidelines been mentioned or explicitly cited used.\n",
    "* `covid` - is DES being used to tackle covid-19 \n",
    "* `sim_software` - name of simulation software or programming language if stated.\n",
    "* `foss_sim` - free and open source simulation software? 0/1\n",
    "* `model_archive` - name of archive if used\n",
    "* `model_repo` - name of model repo if used\n",
    "* `model_journal_supp` - what is stored in the journal supplementary material \n",
    "* `model_personal_org` - name of personal or organisational website if used\n",
    "* `model_platform` - name of cloud platform used (e.g. Binder or Anylogic cloud)\n",
    "* `excluded_reason` - One of four reasons that the study was excluded.\n",
    "\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4208e1-fd49-4ffe-9044-b374856c55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00467fc5-ba2f-4312-95da-edb029dcbf09",
   "metadata": {},
   "source": [
    "## 2. Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cfa583-4d72-4ae3-a6fd-3649235f154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'https://raw.githubusercontent.com/TomMonks/' \\\n",
    "    + 'des_sharing_lit_review/main/data/share_sim_data_extract.zip'\n",
    "\n",
    "FILE_NAME = '../../data/share_sim_data_extract.zip'\n",
    "\n",
    "# used to drop redudant manuscript fields outputted by zotero \n",
    "# e.g. keywords and abstracts.\n",
    "COLS_TO_KEEP = [2, 3, 4, 5, 6, 7, 10, 11, 44, 45, 46, 47, \n",
    "                48, 49, 50, 51, 52, 52, 53, 54, 55, 57]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a1106-1c11-437d-977a-85ae9c379f0f",
   "metadata": {},
   "source": [
    "## 3. Function to read and clean dataset\n",
    "\n",
    "We have implemented the read and clean up of the dataset using `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93217605-6038-4ea8-9505-933d5f93b68e",
   "metadata": {},
   "source": [
    "### 3.1 Cleaning helper functions\n",
    "\n",
    "Two supporting functions are defined for the main routine.  These trim redundant columns and convert all column names to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac35b86f-4865-49b8-9413-dda6181f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_columns(df):\n",
    "    '''\n",
    "    Remove fields that are not needed for the clean\n",
    "    analysis dataset.\n",
    "    \n",
    "    Uses the COLS_TO_KEEP constant list.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    df - pd.DataFrame\n",
    "        The raw data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    return df[df.columns[COLS_TO_KEEP]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d077d3-f58b-4a96-a485-6aeda05b17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_to_lower(df):\n",
    "    '''\n",
    "    Convert all column names in a dataframe to lower case\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    df - pandas.DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "    '''\n",
    "    new_cols = [c.lower() for c in df.columns]\n",
    "    df.columns = new_cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f2163-a2c2-48c2-8edc-5717f860669f",
   "metadata": {},
   "source": [
    "### 3.2. Main load and clean function\n",
    "\n",
    "The main function makes use of pandas method chaining functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a624d26-875e-476a-9e60-d89c5e084245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(file_name):\n",
    "    '''\n",
    "    Loads a cleaned verion of the dataset\n",
    "    \n",
    "    1.  Trims the columns to only those relevant to the analysis\n",
    "    2.  Replaces space in the column names with \"_\"\n",
    "    3.  Converts all column names to lower case\n",
    "    4.  Convert relevant cols to Categorical data type\n",
    "    5.  Performs remaining type conversions.\n",
    "    '''\n",
    "    labels = {'Item Type': 'item_type',\n",
    "               'Publication Year': 'pub_yr',\n",
    "               'Publication Title': 'pub_title'}\n",
    "\n",
    "    type_conversions = {'pub_yr': 'int'}\n",
    "    \n",
    "    recoded_types = {'item_type': {'bookSection':'book'},\n",
    "                     'reporting_guidelines_mention': {'ISPOR-SMDM': 'ISPOR',\n",
    "                                                      '0': 'None'}}\n",
    "\n",
    "    clean = (pd.read_csv(file_name)\n",
    "             .pipe(trim_columns)\n",
    "             .rename(columns=labels) \n",
    "             .pipe(cols_to_lower)\n",
    "             .replace(recoded_types)\n",
    "             .assign(study_included=lambda x: \n",
    "                         pd.Categorical(x['study_included']),\n",
    "                     model_code_available=lambda x: \n",
    "                         pd.Categorical(x['model_code_available']),\n",
    "                     reporting_guidelines_mention=lambda x: \n",
    "                         pd.Categorical(x['reporting_guidelines_mention']),\n",
    "                     covid=lambda x: pd.Categorical(x['covid']),\n",
    "                     foss_sim=lambda x: pd.Categorical(x['foss_sim']),\n",
    "                     item_type=lambda x: pd.Categorical(x['item_type']))\n",
    "            #.astype(type_conversions)\n",
    "            \n",
    "    )\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc4413-bd9e-4c52-a053-f04e468bb0e6",
   "metadata": {},
   "source": [
    "## 4.  Example read in, clean.\n",
    "\n",
    "Here we run the preprocessing of the main dataset and then examine the `DataFrame` information and peak at the head and tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51acd869-a6dd-4f9c-b8ed-1ae040fbb38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 566 entries, 0 to 565\n",
      "Data columns (total 22 columns):\n",
      " #   Column                        Non-Null Count  Dtype   \n",
      "---  ------                        --------------  -----   \n",
      " 0   key                           566 non-null    object  \n",
      " 1   item_type                     566 non-null    category\n",
      " 2   pub_yr                        561 non-null    float64 \n",
      " 3   author                        565 non-null    object  \n",
      " 4   title                         566 non-null    object  \n",
      " 5   pub_title                     539 non-null    object  \n",
      " 6   doi                           498 non-null    object  \n",
      " 7   url                           442 non-null    object  \n",
      " 8   study_included                566 non-null    category\n",
      " 9   model_code_available          492 non-null    category\n",
      " 10  reporting_guidelines_mention  492 non-null    category\n",
      " 11  covid                         494 non-null    category\n",
      " 12  sim_software                  493 non-null    object  \n",
      " 13  foss_sim                      492 non-null    category\n",
      " 14  model_archive                 4 non-null      object  \n",
      " 15  model_repo                    21 non-null     object  \n",
      " 16  model_journal_supp            6 non-null      object  \n",
      " 17  model_journal_supp            6 non-null      object  \n",
      " 18  model_personal_org            5 non-null      object  \n",
      " 19  model_platform                11 non-null     object  \n",
      " 20  available_on_req              49 non-null     object  \n",
      " 21  excluded_reason               80 non-null     object  \n",
      "dtypes: category(6), float64(1), object(15)\n",
      "memory usage: 75.2+ KB\n"
     ]
    }
   ],
   "source": [
    "clean = load_clean_dataset(FILE_NAME)\n",
    "clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b893274-b5fe-494a-b433-a7c6ed0d42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff9536-fc69-4eb1-b3cb-73232adc45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.tail(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
